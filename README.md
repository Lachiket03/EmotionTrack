# EmotionTrack
Emotion Detection via Image &amp; Live Camera Feed  This project leverages deep learning and computer vision to detect emotions from static images and real-time camera feeds.

Emotion Detection via Image & Live Camera Feed

ğŸ“Œ Project Overview

This project is an AI-powered Emotion Detection system that analyzes human facial expressions from both static images and real-time webcam feeds. It utilizes deep learning and computer vision techniques to classify emotions into categories such as Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise.

ğŸš€ Features

Real-time emotion detection using a webcam.

Emotion classification from static images.

Uses Haarcascade classifiers for face and eye detection.

Pre-trained deep learning model (mod1.h5) for emotion recognition.

Structured dataset for training and testing.

Built using OpenCV, TensorFlow/Keras, and deep learning models.

ğŸ› ï¸ Technologies Used

Python (Primary programming language)

OpenCV (Image processing and real-time video analysis)

TensorFlow/Keras (Deep learning model for emotion classification)

NumPy & Pandas (Data handling and preprocessing)

Matplotlib & Seaborn (For data visualization)

ğŸ“Š Model Training

The emotion recognition model (mod1.h5) was trained using emotion_recognization.ipynb on a structured dataset stored in dataset/training/ and dataset/test/. The dataset consists of images categorized into seven emotions:

Angry

Disgust

Fear

Happy

Neutral

Sad

Surprise

ğŸ“œ License

This project is licensed under the MIT License. Feel free to use and modify it for personal and educational purposes.

ğŸ¤ Contributing

Contributions are welcome! If you have suggestions or improvements, feel free to open an issue or submit a pull request.

