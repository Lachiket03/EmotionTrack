# EmotionTrack
Emotion Detection via Image &amp; Live Camera Feed  This project leverages deep learning and computer vision to detect emotions from static images and real-time camera feeds.

Emotion Detection via Image & Live Camera Feed

üìå Project Overview

This project is an AI-powered Emotion Detection system that analyzes human facial expressions from both static images and real-time webcam feeds. It utilizes deep learning and computer vision techniques to classify emotions into categories such as Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise.

üöÄ Features

Real-time emotion detection using a webcam.

Emotion classification from static images.

Uses Haarcascade classifiers for face and eye detection.

Pre-trained deep learning model (mod1.h5) for emotion recognition.

Structured dataset for training and testing.

Built using OpenCV, TensorFlow/Keras, and deep learning models.

üõ†Ô∏è Technologies Used

Python (Primary programming language)

OpenCV (Image processing and real-time video analysis)

TensorFlow/Keras (Deep learning model for emotion classification)

NumPy & Pandas (Data handling and preprocessing)

Matplotlib & Seaborn (For data visualization)


Download the FER-2013 dataset from [here]([https://drive.google.com/file/d/1X60B-uR3NtqPd4oosdotpbDgy8KOfUdr/view?usp=sharing](https://drive.google.com/file/d/1taqe1xWvRSA_gLIFFu7TyNHYSEZptIcI/view?usp=sharing))


üìä Model Training

The emotion recognition model (mod1.h5) was trained using emotion_recognization.ipynb on a structured dataset stored in dataset/training/ and dataset/test/. The dataset consists of images categorized into seven emotions:

Angry

Disgust

Fear

Happy

Neutral

Sad

Surprise

üìú License

This project is licensed under the MIT License. Feel free to use and modify it for personal and educational purposes.

ü§ù Contributing

Contributions are welcome! If you have suggestions or improvements, feel free to open an issue or submit a pull request.

